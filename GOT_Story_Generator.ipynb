{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GOT Story Generator.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jctg97/NLG/blob/master/GOT_Story_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovWeaj7O05dI",
        "colab_type": "text"
      },
      "source": [
        "# **Game of Thrones Story Generator**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0us2wCsc1DFM",
        "colab_type": "text"
      },
      "source": [
        "José Carlos Tollar Gracía"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRSVxpG41Hf5",
        "colab_type": "text"
      },
      "source": [
        "Source = https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSkgbgvU2x2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "059e0903-6466-4e3d-8cef-1f912c87d32b"
      },
      "source": [
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.utils.data_utils import get_file\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "ReadFromDrive = False"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGm_Gu5D2Oro",
        "colab_type": "text"
      },
      "source": [
        "Read dataset form /content/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rO8n2hWlSKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa6145a8-a4c1-4cd6-8626-0bb292f86e68"
      },
      "source": [
        "if not ReadFromDrive:\n",
        "  path = \"gameofthrones.txt\"\n",
        "  with io.open(path, encoding='utf-8') as f:\n",
        "      text = f.read().lower()\n",
        "  print('corpus length:', len(text))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 1020562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YMWyi941ova",
        "colab_type": "text"
      },
      "source": [
        "Read dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvoM5vQ570H3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if ReadFromDrive:\n",
        "  drive.mount('/content/gdrive')\n",
        "  path = \"/content/gdrive/My Drive/NLG/gameofthrones.txt\"\n",
        "  with io.open(path, encoding='utf-8') as f:\n",
        "      text = f.read().lower()\n",
        "  print('corpus length:', len(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkOhk_j-UkMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45e9b9aa-c58f-4cfd-9100-647e40876033"
      },
      "source": [
        "#processing data\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 43\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9WsMqUKUx9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b75759fb-92e6-4089-d2b4-15cc437fb446"
      },
      "source": [
        "# cut the text in semi-redundant sequences of 40 characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 340174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqDAL4WkUzi4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d0a54ee-7c6b-46cd-b479-e058ddf96f18"
      },
      "source": [
        "# Vectorization\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncepL7OBU1v2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "14a3b560-137c-4a6a-b195-1aec243e7a18"
      },
      "source": [
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8wSKz9iU3eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ3grHDmU6V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOYujB2gU8vB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_new_story():\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.3]:\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(3000):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8ZFo7AqVDui",
        "colab_type": "code",
        "outputId": "a18c3e76-af65-46ee-dc58-3e7ec874c5bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=512,\n",
        "          epochs=10,\n",
        "         )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/10\n",
            "340174/340174 [==============================] - 42s 124us/step - loss: 1.9433\n",
            "Epoch 2/10\n",
            "340174/340174 [==============================] - 38s 113us/step - loss: 1.5669\n",
            "Epoch 3/10\n",
            "340174/340174 [==============================] - 39s 115us/step - loss: 1.4564\n",
            "Epoch 4/10\n",
            "340174/340174 [==============================] - 38s 112us/step - loss: 1.3996\n",
            "Epoch 5/10\n",
            "340174/340174 [==============================] - 39s 116us/step - loss: 1.3620\n",
            "Epoch 6/10\n",
            "340174/340174 [==============================] - 40s 116us/step - loss: 1.3368\n",
            "Epoch 7/10\n",
            "340174/340174 [==============================] - 39s 116us/step - loss: 1.3170\n",
            "Epoch 8/10\n",
            "340174/340174 [==============================] - 39s 114us/step - loss: 1.3007\n",
            "Epoch 9/10\n",
            "340174/340174 [==============================] - 39s 115us/step - loss: 1.2882\n",
            "Epoch 10/10\n",
            "340174/340174 [==============================] - 38s 111us/step - loss: 1.2778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f03ee639f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yusBa-m5cf-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1c40f48f-a005-4e5a-e837-9de2ecf2c175"
      },
      "source": [
        "print_new_story()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----- Generating with seed: \"ran might wake up,” robb said, “afraid o\"\n",
            "ran might wake up,” robb said, “afraid of you steel with a fingers and the steward was looked at the story she could see the step. “the maester she was down the wall of the stark. the stream was a stream from the stark of the starks of his face. “we are the flames in the stone and i will not been a second, and the seven kingdoms and he was a brother of the strangers. the seven knight of men and robb stark was a second of the stark. she was a window and the strougdless and the strangers and a boy of the woold with a silvereves and stark. the eyes were come and so men strongers. the street of the night’s watch was still and he had told him. when he looked at the fire looked at his shoulders of his hands. “i will not be with his mounted and man still and suck and her brother of the steps of the stranger and men and lord cherce of the way a hand of his hands. it was a silverever and stark in the steps of the steps of his window. the steward and she was a hand. “you say, and i will not seen a silver of it in his face. “i have her left to the stark of the fast of the strow. it was a golden stark, and she was a fatters of the seven kingdoms and he had been a man and the strange was so his sword with a fingers and the she was a strangers. the steps was a son of the horse the secrets of the hand of the heavy window. the starks were too little in the common to be with the wall of the man with a dozen conqueron who commander stark was to the steps of the story and who had been and the strangers and went a sweed with a strange of the fire and the steps of the room. the seven king of the man with a second window the step. “i will not been a man is a servants and a man with his face from the strenger and the seven kingdoms and he says to the stewn forth to the stark, and the seven keep her hands and warm to see winterfell and silvered and began to stepped to the silvered the grace of the step. he was a short and strow robb stark of the strange of the gods. and the seven keep her head with a second and servant to her brother. “i will not be a second of the wall and the seven kingdoms and went to the soft of a servants of the stone and a silvered and the septa mordan stopped and the strangely and bread and stark in the stranger, and he had no servant to lord arryn with a fingers in the stark. “whatever the others and the gods of the starks of his wooden of his shoulders and ready to the step. he was a heaving were strangers. “we wanted to see the gods. the step. the steward was so much and hands and a horse and all to bring a father’s grace with a strangers. the seven knight of the starks of the targerss of the starks of his grace with the others, the steward was a second window to the strangers. the starks were too lord fiels and fool of the seven kingdoms and wanters of the stone of the story and surely. “he would not be a fatters. it was surely. he was a flames. he saw the second of the stone and walked of the sweet sweet of his hands. he said with a fingers of the string on the stark. “the gods we\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}